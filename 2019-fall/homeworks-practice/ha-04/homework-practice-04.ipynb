{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "# Практическое задание 4\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 28 октября 2019\n",
    "\n",
    "Мягкий дедлайн: 7:59MSK 11 ноября 2019 (за каждый день просрочки снимается 1 балл)\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 13 ноября 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### О задании\n",
    "\n",
    "В этом задании вы:\n",
    "- настроите метод опорных векторов, визуализируете опорные вектора\n",
    "- познакомитесь с калибровочными кривыми и сравните вероятности, выдаваемые логистической регрессией и методом опорных векторов\n",
    "- изучите методы работы с категориальными переменными\n",
    "- в качестве бонуса попробуете библиотеку vowpal wabbit.\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "\n",
    "### Формат сдачи\n",
    "Для сдачи задания переименуйте получившийся файл *.ipynb в соответствии со следующим форматом: homework-practice-04-Username.ipynb, где Username — ваша фамилия и имя на латинице именно в таком порядке (например, homework-practice-04-IvanovIvan.ipynb).\n",
    "\n",
    "Для удобства проверки самостоятельно посчитайте свою максимальную оценку (исходя из набора решенных задач) и укажите ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оценка:** ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T18:11:48.202066Z",
     "start_time": "2019-10-16T18:11:46.362572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Метод опорных векторов и калибровка вероятностней"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T07:36:04.765536Z",
     "start_time": "2018-10-12T07:35:57.814973Z"
    }
   },
   "source": [
    "Сгенерируем синтетические данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T18:11:50.932537Z",
     "start_time": "2019-10-16T18:11:50.752839Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=100000, n_features=20, n_informative=15, n_redundant=5,\n",
    "    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Обучение и применение метода опорных векторов.\n",
    "\n",
    "__(1 балл)__\n",
    "\n",
    "Обучите метод опорных векторов. На занятиях мы проходили обычный вариант, что соответствует линейному ядру (LinearSVC/LinearSVR в scikit-learn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:39:43.088969Z",
     "start_time": "2018-10-11T20:39:43.084985Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(),\n",
    "                    svm.LinearSVC())\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой части посчитайте ROC-AUC, PR-AUC. Постройте ROC и PR кривые."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "roc_auc_area = roc_auc_score(y_test, y_pred)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 2\n",
    "plt.plot(fpr, tpr, lw=lw, color='darkorange', \n",
    "         label='ROC curve (area = {})'.format(roc_auc_area))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В названии метода присутствуют некоторые \"опорные векторы\". Сгенерируйте синтетический датасет с помощью make_classification с 2 признаками, обучите на нём метод опорных векторов. Визуализируйте разделяющую прямую, все объекты и выделите опорные вектора (атрибут support\\_vectors\\_). В этот раз вместо LinearSVC воспользуйтесь SVC с линейным ядром (kernel='linear'), так как только в нём есть информация об опорных векторах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=2, n_informative=1, n_redundant=0, n_clusters_per_class=1,\n",
    "    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(),\n",
    "                    svm.SVC(kernel='linear'))\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "\n",
    "# plot the decision function\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "           linestyles=['--', '-', '--'])\n",
    "\n",
    "# plot support vectors\n",
    "ax.scatter(clf['svc'].support_vectors_[:, 0], clf['svc'].support_vectors_[:, 1], s=100,\n",
    "           linewidth=1, facecolors='none', edgecolors='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__ Калибровка вероятностей.\n",
    "\n",
    "__(1.5 балла)__\n",
    "\n",
    "Перейдём к оценке качества выдаваемых алгоритмами вероятностей. Начнём с калибровочных кривых. \n",
    "\n",
    "Допустим, алгоритм возвращает некоторые числа от нуля до единицы. Хорошо ли они оценивают вероятность? Для этого разобьем отрезок $[0, 1]$ на несколько маленьких отрезков одинаковой длины. Рассмотрим $i$-й отрезок с границами $[a_i, b_i]$ и предсказания $p_1, p_2, \\dots, p_k$, которые попали в него. Пусть им соответствуют истинные ответы $y_1, y_2, \\dots, y_k$. Если алгоритм выдает корректные вероятности, то среди этих истинных ответов должно быть примерно $(a_i + b_i) / 2$ единиц. Иными словами, если нарисовать кривую, у которой по оси X отложены центры отрезков, а по оси Y — доли единичных ответов этих в отрезках, то она должна оказаться диагональной. Ниже приведена функция, которая должна рисовать такие кривые. В ней допущено две ошибки — найдите и исправьте их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration_curve(y_test, preds):\n",
    "    bin_middle_points = []\n",
    "    bin_real_ratios = []\n",
    "    n_bins = 20\n",
    "    for i in range(n_bins):\n",
    "        l = 1.0 / n_bins * i\n",
    "        r = 1.0 / n_bins * (i + 1)\n",
    "        bin_middle_points.append((l + r) / 2)\n",
    "        bin_real_ratios.append(np.mean(y_test[(preds >= l) & (preds < r)] == 1))\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.plot(bin_middle_points, bin_real_ratios, marker='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте калибровочные кривые для логистической регрессии и метода опорных векторов. Изучите распределение ответов классификаторов (постройте гистограммы с помощью plt.hist). Чем они различаются? Чем вы можете объяснить это?\n",
    "\n",
    "Заметим, что метод опорных векторов не умеет predict_proba, но имеет метод decision_function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=100000, n_features=20, n_informative=15, n_redundant=0,\n",
    "    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "probs = clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curve(y_test, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fop, mpv = calibration_curve(y_test, probs, n_bins=20)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(mpv, fop, marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(probs, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью калибровочной кривой мы можем определить соответствие значений целевой переменной y_test и вероятностей, которые выдает классификатор. Она представляет из себя возрастающую диагональ, которая означает, что с каждым бином количество единиц в бине растет практически линейно. \n",
    "\n",
    "С помощью гистограммы мы можем видеть, какая доля объектов из тестового набора данных получила опереденную вероятность. Мы не можем явно сравнить вероятности с метками 0/1, но у нас есть понимание по тому, сколько точек попало в каждый из бинов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуйтесь CalibratedClassifierCV из sklearn для калибровки вероятностей метода опорных векторов на обучении и постройте с его помощью предсказания для тестовой выборки. Нарисуйте для них калибровочную кривую. Улучшилась ли она?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel='linear')\n",
    "calibrated = CalibratedClassifierCV(model, method='sigmoid', cv=5)\n",
    "calibrated.fit(X_train, y_train)\n",
    "\n",
    "probs = calibrated.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curve(y_test, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Бонусное задание (1 балл).__ Реализуйте свою функцию для калибровки вероятностей. Опишите ваш подход и продемонстрируйте результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Работа с категориальными переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части мы научимся обрабатывать категориальные переменные, так как закодировать их в виде чисел недостаточно (это задаёт некоторый порядок, которого на категориальных переменных может и не быть). Существует два основных способа обработки категориальных значений:\n",
    "- One-hot-кодирование\n",
    "- Счётчики (CTR, mean-target кодирование, ...) — каждый категориальный признак заменяется на среднее значение целевой переменной по всем объектам, имеющим одинаковое значение в этом признаке.\n",
    "\n",
    "Начнём с one-hot-кодирования. Допустим наш категориальный признак $f_j(x)$ принимает значения из множества $C=\\{c_1, \\dots, c_m\\}$. Заменим его на $m$ бинарных признаков $b_1(x), \\dots, b_m(x)$, каждый из которых является индикатором одного из возможных категориальных значений:\n",
    "$$\n",
    "b_i(x) = [f_j(x) = c_i]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:41:54.913436Z",
     "start_time": "2018-10-11T20:41:54.907515Z"
    }
   },
   "source": [
    "__Подготовка данных.__\n",
    "\n",
    "Загрузим данные с прошлогоднего конкурса  [Kaggle Porto Seguro’s Safe Driver Prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction) (вам нужна только обучающая выборка). Задача состоит в определении водителей, которые в ближайший год воспользуются своей автомобильной страховкой (бинарная классификация). Но для нас важна будет не сама задача, а только её данные. При этом под нужды задания мы немного модифицируем датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T07:36:04.765536Z",
     "start_time": "2018-10-12T07:35:57.814973Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', index_col=0)\n",
    "target = data.target.values\n",
    "data = data.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пересемплируем выборку так, чтобы положительных и отрицательных объектов в выборке было одинаковое число. Разделим на обучающую и тестовую выборки.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T07:36:05.368407Z",
     "start_time": "2018-10-12T07:36:04.770388Z"
    }
   },
   "outputs": [],
   "source": [
    "# some resampling\n",
    "np.random.seed(910)\n",
    "mask_plus = np.random.choice(np.where(target == 1)[0], 100000, replace=True)\n",
    "mask_zero = np.random.choice(np.where(target == 0)[0], 100000, replace=True)\n",
    "\n",
    "data = pd.concat((data.iloc[mask_plus], data.iloc[mask_zero]))\n",
    "target = np.hstack((target[mask_plus], target[mask_zero]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 3.__ Посчитайте качество (в этом задании будем работать c ROC-AUC) на исходных признаках при применении логистической регрессии.\n",
    "\n",
    "__(0 баллов)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(roc_auc_score(y_train, y_train_pred))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4.__ Закодируйте все категориальные признаки с помощью one-hot-кодирования. Обучите логистическую регрессию и посмотрите, как изменилось качество модели (с тем, что было до кодирования). Измерьте время, потребовавшееся на обучение модели.\n",
    "\n",
    "__(0.5 балла)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [s for s in X_train.columns if 'cat' in s]\n",
    "X_train_cat = X_train[categorical]\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_cat = enc.fit_transform(X_train_cat)\n",
    "X_train_cat = pd.DataFrame(X_train_cat.toarray(), \n",
    "                           columns=['ohe_{}'.format(i) for i in range(X_train_cat.shape[1])],\n",
    "                           index=X_train.index)\n",
    "X_test_cat = enc.transform(X_test[categorical])\n",
    "X_test_cat = pd.DataFrame(X_test_cat.toarray(), \n",
    "                          columns=['ohe_{}'.format(i) for i in range(X_test_cat.shape[1])],\n",
    "                          index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat((X_train.drop(columns=categorical), X_train_cat), axis=1)\n",
    "X_test = pd.concat((X_test.drop(columns=categorical), X_test_cat), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(roc_auc_score(y_train, y_train_pred))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно было заменить, one-hot-кодирование может сильно увеличивать количество признаков в датасете, что сказывается на памяти, особенно, если некоторый признак имеет большое количество значений. Эту проблему решает другой способ кодирования категориальных признаков — счётчики. Основная идея в том, что нам важны не сами категории, а значения целевой переменной, которые имеют объекты этой категории. Каждый категориальный признак мы заменим средним значением целевой переменной по всем объектам этой же категории:\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)][y_i = +1]}{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)]}\n",
    "$$\n",
    "\n",
    "__Задание 5.__ Закодируйте категориальные переменные с помощью счётчиков (ровно так, как описано выше без каких-либо хитростей). Обучите логистическую регрессию и посмотрите на качество модели на тестовом множестве. Сравните время обучения с предыдущим экспериментов. Заметили ли вы что-то интересное?\n",
    "\n",
    "__Ответ:__ Видимо, данные target'а утекли в данные, из-за чего качество упало.\n",
    "\n",
    "__(1.5 балла)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = data[categorical]\n",
    "data_cat['target'] = target\n",
    "\n",
    "for cat_feature in categorical:\n",
    "    data[cat_feature] = data_cat.groupby(cat_feature)['target'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(roc_auc_score(y_train, y_train_pred))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отметим, что такие признаки сами по себе являются классификаторами и, обучаясь на них, мы допускаем \"утечку\" целевой переменной в признаки. Это ведёт к переобучению, поэтому считать такие признаки необходимо таким образом, чтобы при вычислении для конкретного объекта его целевая метка не использовалась. Это можно делать следующими способами:\n",
    "1. Вычислять значение счётчика по всем объектам расположенным выше в датасете (например, если у нас выборка отсортирована по времени).\n",
    "2. Вычислять по фолдам, то есть делить выборку на некоторое количество частей и подсчитывать значение признаков по всем фолдам кроме текущего (как делается в кросс-валидации).\n",
    "3. Внесение некоторого шума в посчитанные признаки. \n",
    "\n",
    "__Задание 6.__ Реализуйте корректное вычисление счётчиков самым простым способом — добавление шума к значениям (необходимо соблюсти баланс между избавление от переобучения и полезностью признаков). Снова обучите логистическую регрессию, оцените качество. Сделайте выводы.\n",
    "\n",
    "__(1 балл)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0\n",
    "std = 0.01\n",
    "size = data.shape[0]\n",
    "for cat_feature in categorical:\n",
    "    data[cat_feature] += np.random.normal(m, std, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict_proba(X_test)[:, 1]\n",
    "print(roc_auc_score(y_train, y_train_pred))\n",
    "\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(Бонусная часть)__ Посчитайте корректные счётчики первым или вторым способов из описанных выше (не забудьте добавить и шум). \n",
    "\n",
    "__(+0.5 балла)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь ответьте на следующий вопрос: что будет, если некоторая категория встречается в выборке всего несколько раз? По этой причине производится сглаживание счётчиков. Например, на практике хорошие результаты показывает использование сглаживания средним по всей выборке:\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)][y_i = +1] + C \\times global\\_mean}{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)] + C}\n",
    "$$\n",
    "где $global\\_mean$ — среднее значение целевой переменной по всей выборке, $C$ — параметр, определяющий степень сглаживания (например, можно использовать 10 или подобрать для каждого признака свой). Основная идея в том, что мы \"разбавляем\" среднее значение по некоторой категории глобальным средним значении. И тем меньше, чем большее количество объектов этой категории встречается в выборке. \n",
    "\n",
    "Однако для сглаживания вместо среднего значения целевой переменной можно использовать любое другое значение от 0 до 1 (этот параметр иногда называют $prior$). Можно сделать несколько признаков с разными значениями параметра. На практике в задачах бинарной классификации полезными бывают даже отрицательные значения!\n",
    "\n",
    "__Задание 7.__ Добавьте сглаживание, описанное выше и повторите эксперименты.\n",
    "\n",
    "__(1 балл)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', index_col=0)\n",
    "target = data.target.values\n",
    "data = data.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some resampling\n",
    "np.random.seed(910)\n",
    "mask_plus = np.random.choice(np.where(target == 1)[0], 100000, replace=True)\n",
    "mask_zero = np.random.choice(np.where(target == 0)[0], 100000, replace=True)\n",
    "\n",
    "data = pd.concat((data.iloc[mask_plus], data.iloc[mask_zero]))\n",
    "target = np.hstack((target[mask_plus], target[mask_zero]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = data[categorical]\n",
    "data_cat['target'] = target\n",
    "\n",
    "global_mean = data_cat['target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0.1\n",
    "for cat_feat in categorical:\n",
    "    agg_stat = data_cat.groupby(cat_feat)['target'].agg(['count', 'mean'])\n",
    "    counts = agg_stat['count']\n",
    "    means = agg_stat['mean']\n",
    "    smoothed_means = (counts * means + C * global_mean) / (counts + means)\n",
    "    data[cat_feat] = data[cat_feat].map(smoothed_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict_proba(X_train)[:, 1]\n",
    "print(roc_auc_score(y_train, y_train_pred))\n",
    "\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Замечание.__ Усложнение методов вычисления счётчиков не делают результаты модели гарантированно лучше. Особенно с учётом того, что логистическая регрессия не такая сложная модель, чтобы переобучаться. Поэтому вы необязательно должны были получать на каждом шаге всё лучшие и лучшие результаты (но необходимые результаты у вас должны были получиться).\n",
    "\n",
    "Как вы должны были заметить, счётчики являются хорошей альтернативой one-hot-кодированию. Напишите, какие плюсы и минусы использования счётчиков по сравнению с one-hot-кодированием, вы заметили.\n",
    "\n",
    "__Ответ:__\n",
    "Плюсы:\n",
    "1. Не увеличивают количество признаков.\n",
    "2. Не являются линейно-зависимыми признаками, в отличие от one-hot.\n",
    "\n",
    "Минусы:\n",
    "1. Могут быть утечки target'а в признаки.\n",
    "2. Непростая схема подсчета при честном вычислении mean-target encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важной частью процесса построения модели является отбор признаков. На практике многие признаки оказывают малое влияние на модель (при этом их расчёт занимает время) или даже негативно сказываются на качестве модели. Попробуем несколько подходов отбора признаков, оценим, как они влияют на качество модели и сколько времени занимают.\n",
    "\n",
    "Обратимся к тому же датасету про обращение клиентов по страховым случаям. Обойдёмся без сэмплирования объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T07:36:04.765536Z",
     "start_time": "2018-10-12T07:35:57.814973Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', index_col=0)\n",
    "target = data.target.values\n",
    "data = data.drop('target', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=124)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы помните, в данных много категориальных признаков. Давайте закодируем их с помощью one-hot кодирования. Исходные колонки с категориальными признаками можно удалить. Сколько признаков мы получили?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [feat for feat in data.columns if 'cat' in feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_cat = enc.fit_transform(X_train[categorical_features])\n",
    "X_test_cat = enc.transform(X_test[categorical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat = pd.DataFrame(X_train_cat.toarray(), \n",
    "                           columns=['ohe_{}'.format(i) for i in range(X_train_cat.shape[1])],\n",
    "                           index=X_train.index)\n",
    "X_test_cat = pd.DataFrame(X_test_cat.toarray(), \n",
    "                          columns=['ohe_{}'.format(i) for i in range(X_test_cat.shape[1])], \n",
    "                          index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=categorical_features)\n",
    "X_test = X_test.drop(columns=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, X_train_cat], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве основной модели будем использовать логистическую регрессию, а целевой метрики — ROC-AUC. Обучите модель и посчитайте качество на тестовой выборке. Давайте запомним полученное значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.638065555662342\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Встроенные методы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, мы хотим оставить только 200 лучших признаков. Попробуем сделать это несколькими способами.\n",
    "\n",
    "Начнём с отборам признаков с помощью линейной модели. Как известно, веса линейной модели означают вклад каждого признака в предсказание модели, а значит, модуль этого вклада можно интерпретировать как важность признаков. Такой метод отбора называются встроенным или embedded methods, так как он заложен в особенности модели.\n",
    "\n",
    "__Задание 8.__ Оставьте 200 признаков с наибольшим модулем соответсвующего параметра линейной модели. Обучите модели заново и оцените её качество. Замерьте скорость такого отбора признаков.\n",
    "\n",
    "Изменилось ли качество? Как?\n",
    "\n",
    "__(0.5 балла)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns\n",
    "abs_values = np.abs(clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = [x[0] for x in \n",
    "                    sorted(list(zip(X_train.columns.values, abs_values)), key=lambda x: x[1], reverse=True)[200:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=features_to_drop)\n",
    "X_test = X_test.drop(columns=features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6382768610729027\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь давайте подумаем, что мы не учли. Мы предположили, что признаки вносят вклад равномерно, но не учли их масштаба. Если мы умножим один из признаков в 100 раз, то без учёта регуляризации его вес уменьшится в эти же 100 раз. А мы на основе этого отбираем признаки! Давайте сначала отнормируем признаки одним из способов, а только потом будем удалять признаки. \n",
    "\n",
    "Кстати, в таком случае надо пересчитать качество на всех признаках (сделайте это ниже). Если вы сделали нормирование признаков в самом начале, то попробуйте отобрать признаки на неотмасштабированных данных.\n",
    "\n",
    "Что получилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', index_col=0)\n",
    "target = data.target.values\n",
    "data = data.drop('target', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [feat for feat in data.columns if 'cat' in feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [feat for feat in X_train.columns if 'bin' not in feat and 'cat' not in feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6340638269389018\n"
     ]
    }
   ],
   "source": [
    "column_transformer = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    ('scaling', StandardScaler(), numeric_features)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('ohe_and_scaling', column_transformer),\n",
    "    ('classification', LogisticRegression(max_iter=10000))\n",
    "])\n",
    "\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы фильтрации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте отбирать признаки умнее, а именно через подсчёт некоторой функции для каждого признака. На основании значений этой функции будем оставлять наиболее важные признаки. Методы этого семейства называют фильтрующими или  filter methods. \n",
    "\n",
    "В качестве такой функции будем считать t-статистику:\n",
    "\n",
    "$$t(x) = \\frac{|\\mu_+ - \\mu_-|}{\\sqrt{\\frac{n_+ \\sigma^2_+ + n_- \\sigma^2_-}{n_+ + n_-}}},$$\n",
    "\n",
    "где $mu$, $sigma$, $n$ соответственно среднее, среднеквадратичное отклонение и количество объектов каждого из классов.\n",
    "\n",
    "__Задание 9.__ Оставьте 200 признаков с наибольшим значением и замерьте качество. Не забудьте замерить скорость отбора признаков в этом случаев.\n",
    "\n",
    "__(0.5 балла)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', index_col=0)\n",
    "target = data.target.values\n",
    "#data = data.drop('target', axis=1)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [feat for feat in data.columns if 'cat' in feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [feat for feat in X_train.columns if 'bin' not in feat and 'cat' not in feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_features = [feat for feat in X_train.columns if 'bin' in feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "data_cat = enc.fit_transform(data[categorical_features])\n",
    "data_cat = pd.DataFrame(data_cat.toarray(), \n",
    "                        columns=['ohe_{}'.format(i) for i in range(data_cat.shape[1])],\n",
    "                        index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_num = scaler.fit_transform(data[numeric_features])\n",
    "data_num = pd.DataFrame(data_num, columns=numeric_features, index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data[binary_features], data_cat, data_num, data['target']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_stat(agg_stat):\n",
    "    mean_diff = np.abs(agg_stat['mean'][1] - agg_stat['mean'][0])\n",
    "    denominator = (agg_stat['count'][1] * agg_stat['std'][1] + agg_stat['count'][0] * agg_stat['std'][0])\n",
    "    return  mean_diff / np.sqrt(denominator / (agg_stat['count'][1] + agg_stat['count'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = []\n",
    "for column in data.columns:\n",
    "    if column == 'target':\n",
    "        continue\n",
    "    agg_stat = data.groupby('target')[column].agg(['mean', 'std', 'count'])\n",
    "    feature_importances.append((column, t_stat(agg_stat)))\n",
    "    \n",
    "feature_importances = sorted(feature_importances, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = [x[0] for x in feature_importances[200:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ps_ind_10_bin',\n",
       " 'ohe_115',\n",
       " 'ohe_170',\n",
       " 'ohe_103',\n",
       " 'ohe_39',\n",
       " 'ohe_155',\n",
       " 'ohe_181',\n",
       " 'ohe_20',\n",
       " 'ohe_106',\n",
       " 'ohe_54',\n",
       " 'ohe_130',\n",
       " 'ohe_81',\n",
       " 'ohe_102',\n",
       " 'ps_calc_17_bin',\n",
       " 'ps_calc_07',\n",
       " 'ohe_94',\n",
       " 'ohe_87',\n",
       " 'ps_calc_06',\n",
       " 'ohe_85',\n",
       " 'ohe_79',\n",
       " 'ps_calc_04',\n",
       " 'ohe_171',\n",
       " 'ohe_29',\n",
       " 'ohe_152',\n",
       " 'ohe_108',\n",
       " 'ohe_138',\n",
       " 'ohe_113']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=features_to_drop)\n",
    "y = data['target']\n",
    "data = data.drop(columns='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6308548010419753\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы-обёртки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 10.__ \n",
    "\n",
    "__(1 балл)__\n",
    "\n",
    "Заключительный из рассматриваемых нами методов работает следующим образом: мы исключаем по очереди один из признаков и смотрим, как это влияет на качество. Удаляем признаки таким жадным способом, пока не достигнем некоторого критерия (количество признаков или ухудшением качества).\n",
    "\n",
    "Заметим, что нельзя оценивать качество по тестовой выборке, иначе мы можем переобучиться, как, например, при настройке гиперпараметров. Разделите выборку на 2 части, на одной из них обучайте модель без одного из признаков,  на второй части оценивайте качество. Исходную тестовую выборку стоит использовать только на финальной оценке качества.\n",
    "\n",
    "Сделайте одну итерацию и прикиньте, сколько времени займёт такой отбор признаков. Кажется, что чересчур. Давайте возьмём маленький сэмпл данных (например, в 10 тысяч объектов), что сильно уменьшит время итерации. Теперь это долго, но уже приемлимо. \n",
    "\n",
    "Если это всё ещё долго для вашего комьютера, можете попробовать брать не по одному признаку, а сразу по пять (и удалять сразу тоже по 5). Для этого перед каждой итерацией удаления делите заново все признаки на группы по 5 штук.\n",
    "\n",
    "Снова оставьте только 200 признаков и оцените качество на тестовой выборке. Сколько времени занял такой отбор признаков?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте подведём итоги по отбору признаков. Назовите преимущества и недостатки каждого из методов. Какой метод привёл к наилучшему качеству?\n",
    "\n",
    "**Ответ:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройка порога для бинаризации вероятностей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части мы будем проделывать стандартные операции для подготовки модели к её реальному использованию — подбора порога для бинаризации вероятностей с учётом потребностей бизнеса или продукта. Хороший алгоритм с точки зрения ROC-AUC это, конечно, хорошо, но ведь в реальности нам надо принимать решение бинарно, например, выдавать ли кредит человеку. \n",
    "\n",
    "Воспользуемся той же самый задачей, что и в предыдущем разделе — определение обращение клиента в страховую в ближайшее время. Положительные объекты в нашей выборки как раз обратившиеся в страховую клиенты. \n",
    "\n",
    "Не вдаваясь в подробности бизнеса страховых, можно понять, что обращение клиента по страховому случаю для нас как страховой невыгодно, ведь мы теряем на этом деньги. Клиенты, которые не обращаются в страховую и ездят аккуратно, приносят нам деньги.\n",
    "\n",
    "Пусть на каждом клиенте, который обратился в нашу страховую, мы теряем 100000, а на клиенте, который не обратился в страховую, мы зарабатываем 5000. \n",
    "\n",
    "Будем строить алгоритм, который прогнозирует обращение по страховому случаю, чтобы некоторым потенциальным клиентам отказывать в обслуживании, если мы уверены, что на них мы потеряем деньги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T07:36:04.765536Z",
     "start_time": "2018-10-12T07:35:57.814973Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', index_col=0)\n",
    "target = data.target.values\n",
    "data = data.drop('target', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=124)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот раз мы не будем сэмплировать данные и будем использовать их \"как есть\".\n",
    "\n",
    "Посчитайте долю положительных примеров в выборке? Скажите, почему она такая?\n",
    "\n",
    "Обратившихся в страховую - всего 3.6%, их и не должно быть много, иначе страховая разорится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.036447517859182946"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы помните, в данных много категориальных признаков. Давайте закодируем их с помощью one-hot кодирования. Исходные колонки с категориальными признаками можно удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [feat for feat in data.columns if 'cat' in feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [feat for feat in X_train.columns if 'bin' not in feat and 'cat' not in feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6340638269389018\n"
     ]
    }
   ],
   "source": [
    "column_transformer = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    ('scaling', StandardScaler(), numeric_features)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('ohe_and_scaling', column_transformer),\n",
    "    ('classification', LogisticRegression(max_iter=10000))\n",
    "])\n",
    "\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве нашей основной модели будем использовать логистическую регрессию, которая возвращает вероятность положительного класса. Обучите модель, сделайте предсказания на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте ROC-AUC. Что вы можете про него сказать? Как вы считаете, почему получилось так?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC-AUC не очень высокий, но у нас и образцов в положительном классе не так много."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте precision-recall кривую на тестовой выборке. Что вы можете по ней сказать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x107053b38>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_precision_recall_curve(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть алгоритм, который определяет вероятность обращения клиента по страховому случаю, но мы хотим использовать этот алгоритм, чтобы отказывать клиентам в обслуживании в страховой. Для этого нам нужны бинарные предсказания алгоритма. Давайте искать этот порог для получения бинарных предсказаний.\n",
    "\n",
    "__Задание 11.__\n",
    "\n",
    "__(0.5 балла)__\n",
    "\n",
    "Предположим, что нам надо подобрать порог такой, чтобы среди наших положителных предсказаний 95\\% действительно обратились бы по страховому случаю. Подберите соответствующий порог, оцените на нём precision, recall. Скажите, какой части потенциальных клиентов мы откажем?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда сложно решить, какие значения precision и recall нужны в нашей задаче. Однако иногда можно оценить экономический эффект от нашего алгоритма. Мы знаем, во сколько нам обходится клиент, который обратился в страховую, и сколько нам приносит клиент, который не обратился. \n",
    "\n",
    "При фиксированном пороге мы знаем, кому мы бы отказали в обслуживании. Среди них есть те, кто обратился бы в страховую и нам пришлось бы потратить деньги, и те, кто не обратился бы, то есть принёс бы нам деньги. Мы можем посчитать разницу между нашими доходами и расходами от этой группы людей и надеяться, что она будет положительной. \n",
    "\n",
    "__Задание 12.__ Найдите такой порог, при котором наш баланс (разница между доходами и расходами на группе клиентов, которым мы отказали) неотрицательный. \n",
    "\n",
    "__(1 балл)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А на каком значение порога это разнциа максимальна? Скольким клиентам мы отказали в обслуживании?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3 (бонус). Vowpal Wabbit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части мы научимся использовать библиотеку [vowpal wabbit](https://github.com/JohnLangford/vowpal_wabbit). У неё есть несколько особенностей:\n",
    "- можно обучать только линейные модели, но за счёт большого количества опций и возможностей по усложнению, можно построить и довольно сложные вещи\n",
    "- можно обучаться на выборках, которые не помещаются в оперативную память\n",
    "- можно обрабатывать большое количество признаков (например, мешки слов текстов) и \"на ходу\" строить на них комбинации (не переделывать датасет)\n",
    "- другие особенности, как например, активное обучение и возможность распараллеленного обучения.\n",
    "\n",
    "Основные особенности при использовании следующие:\n",
    "- Свой формат данных: \"label |A feature1:value1 |B feature2:value2\", позволяющий, во-первых, указывать не все признаки (не нужно хранить много нулей в разреженных данных), а во-вторых, группировать и иметь возможность отключать или взаимодействовать (\"отключать\", добавлять квадратичные признаки и т.д.) сразу со всей группой признаков. По этой причине вам понадобится реализовать конвертер датасета и загрузку своих предсказаний, чтобы посчитать качество предсказаний.\n",
    "- Запуск обучения из командной строки (однако можно запускать эти же команды из ноутбука).\n",
    "\n",
    "В этот раз мы будем использовать данные с конкурса [Kaggle Avazu Click-Through Rate Prediction](https://www.kaggle.com/c/avazu-ctr-prediction) по предсказанию кликов (бинарная классификация). В обучающей выборке 40kk строк, так что у вас не должно быть желания загружать их в оперативную память. Предлагается взять первые 30kk строк в качестве обучающей выборке и оставшуюся часть для тестирования.\n",
    "\n",
    "__Задание 13.__ Работа с vowpal wabbit. \n",
    "\n",
    "- Скачайте данные, разделите их на обучающую и тестовую выборки.\n",
    "- Подготовьте функции для конвертирования датасета в формат vowpal wabbit и для загрузки предсказаний в ноутбук для подсчёта функционала.\n",
    "- Сделайте простейшее решение на vowpal wabbit. Оцените качество.\n",
    "- Изучите возможности и параметры vowpal wabbit. Поэксперементируйте. \n",
    "- Расскажите, что интересного вы узнали (какие-нибудь особенности, режимы работы, фишки, параметры).\n",
    "- Удалось ли вам улучшить качество базовой модели? Насколько? Что ещё можно было бы попробовать?\n",
    "\n",
    "В этом задании предусмотрены баллы по двум критериям:\n",
    "- достижение ROC-AUC на отложенной выборки более 0.738 __(1 балл)__\n",
    "- несколько занимательных фактов и возможностей vowpal-wabbit __(0.5 балла)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_mipt",
   "language": "python",
   "name": "ml_mipt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
